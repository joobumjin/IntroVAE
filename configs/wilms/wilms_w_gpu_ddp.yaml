opt:
  CUDA_VISIBLE_DEVICES: 0
  lr_e: 0.0002 
  lr_g: 0.0002
  lr: 0.0002
  beta1: 0.5
  momentum: 0.9
  clip: 100
  step: 500
  num_vae: 0
  weight_rec: 0.05
  weight_kl: 1.0
  weight_neg: 0.5
  m_plus: 120  
  channels: [32, 64, 128, 256, 512, 512]
  hdim: 512
  
  save_iter: 1 
  test_iter: 1000 
  trainsize: 29000
  nrow: 8
  #trainfiles? 
  dataroot: ~/awesomePhD/Datasets/
  dataset: wilms
  workers: 12
  batchSize: 16 
  input_height: 256
  output_height: 256
  nEpochs: 500 
  start_epoch: 0  
  cuda: True
  outf: ./logs/

  net_E_params:
    cdim: 3
    hdim: 512
    channels: [64, 128, 256, 512, 512, 512]
    image_size: 256
  
  net_D_params:
    cdim: 3
    hdim: 512
    channels: [64, 128, 256, 512, 512, 512]
    image_size: 256


trainer_opt:
  gpus: [0]
  max_steps: 200000
  precision: 32
  max_epochs: 16400
  min_epochs: 1
  log_save_interval: 1000
  num_sanity_val_steps: 1
  early_stop_callback: False
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  deterministic: True 
  #distributed_backend: dp

logging_opt:
  save_dir: ./logs/
  name: wilms
  version: wilms_w

ckpt_opt:
  save_top_k: -1
  period: 1000
